# Applications {#sec-applications}

In this part we will build several applications integrating LLMs in different roles, from frontend chatbots that interact with the user to hidden in the backend. These chapters are best read in order, although they are mostly self-contained, and you can skip some of them if you aren't interested in a particular type of application. In any case, whenever a chapter builds on top of a previous application, we will clearly state it in the corresponding introductory section.

::: {.callout-note}
This part is under construction.
:::

In [Chapter @sec-chatbot] we build our first LLM-powered application: a basic chatbot. We will learn how to set up a conversation loop and how to keep track of previous messages to simulate short-term memory for the bot. We will also learn how to stream messages for a better user experience (simulating a typing animation instead of waiting for the full response).

This one is a must-read chapter, because it will lay the groundwork for the rest of the applications. It is also the only chapter where we'll build the application step by step, showing how to go from zero to a functioning bot. In the rest of the chapters, we'll start with a working application and digest it to understand how it works, but we will move much faster to cover a wider range of functionalities.

Next up, in [Chapter @sec-pdfbot] we tackle our first augmented chatbot: a PDF question-answering system. We will build our own version of a vector store, and learn how to convert a large document into indexable chunks that can be retrieved at query time and injected into the bot prompt.

Leveling up a bit, in [Chapter @sec-search] we build a search-powered chatbot that can browse the web and provide relevant answers with proper citations.

Then, in [Chapter @sec-shoping] we will build a more advanced version of retrieval augmentation. This time is a shoping helper than can search items on behalf of the user, add them to the checkout cart, buy them, and track their delivery status---all based on a simulated online store. We'll learn how to teach an LLM to call methods from an arbitrary API and write our own plugin system.

In [Chapter @sec-analyst] we start playing with chatbots that can execute code on their own. We'll build a very simple data analyst that can answer questions from a CSV file by running Pandas queries and generating charts. We'll learn how to decide whether a textual response or a code/chart is more appropriate and how to generate structured responses.

Next, in [Chapter @sec-cli] we'll take a quick detour from our standard UI to build a command-line bot that has access to your terminal and can run commands on it, so you'll never have to google how to unzip a tar.gz file again.

Jumping from code execution to more traditional text generation, in [Chapter @sec-writer] we'll code a writing assistant that will help us create an article or text document in general. We'll learn prompt techniques to summarize, outline, proofread, and edit textual content. We will also learn how to use an LLM to interactively modify a document, adding, modifying, or deleting arbitrary sections.

And then, building on top of that same workflow, in [Chapter @sec-coder] we build a coding assistant, who can interact with a codebase adding, modifying, refactoring, and deleting code and files.

Up to this point, all we have coded are chatbot-style applications. These are mainly conversational interfaces where the bulk of the interaction is a chat between a user and a model. In the next few chapters, we will distance ourselves from the classic chabot style and start using LLMs as core components in other applications, where sometimes the end user won't directly talk to the language model.

We continue with [Chapter @sec-planner] building a planning tool that can scan our emails and output a structured list of events, activities, TODOs, and integrate them into our calendar.

Then, in [Chapter @sec-feeder] we'll write a feed summarizer to create newsletter digests from a variety of sources, classifying and selecting the most relevant articles according to whatever criteria we desire.

Based on what we have so far, in [Chapter @sec-journal] we'll build an interactive journal that will help you capture our day-to-day thoughts and reflections, summarize your achievements and goals, and provide guidance.

In [Chapter @sec-graph] we'll build an ontology learning tool that can create a knowledge graph from an arbitrary corpus of data, detecting entities and relations, and then ask questions about it. We will learn how to prompt an LLM for structured information extraction, and how to augment prompts with graph-like information.

Building on the previous functionality, in [Chapter @sec-research] we'll build a research assistance tool that can create complete reports on an arbitrary topic by locating relevant articles, extracting information, summarizing key points, and constructions tables and graphics.

And then things will turn to weird and nerd side. In [Chapter @sec-dnd] we will write a small but complete text-based fantasy game, using and LLM for everything from world and character design to dialogues and interactions. We'll learn how to ground the LLM in an actual world model to avoid hallucinations and enable a consistent gameplay.

And finally, in [Chapter @sec-storyteller] we will build a fully automate storyteller that can weave a consistent story with simulated characters who have goals and necesities, interact with each other, and learn by navigating a consistent world. These last two chapters are more towards pushing the boundary of what current language models can do, to give you a glimpse of the near future.

And that's it! At least, that's the plan for now. 15 applications of LLMs to the most varied problems, many of which could become the _Product Hunt_ product of the day if you take them to completion.
